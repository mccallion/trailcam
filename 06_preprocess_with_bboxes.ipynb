{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f15ec5a",
   "metadata": {},
   "source": [
    "# Using a bounding box model to preprocess our images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c28ec9",
   "metadata": {},
   "source": [
    "In the previous notebook, we trained a classifier to a very high accuracy (low error) but discovered that it underperformed on our trailcam ground-truth data. Fortunately, we also discovered a possible way forward: preprocessing the trailcam images by cropping them tightly around any animal \"instances\". (In computer vision jargon, an \"instance\" is a single object in an image. An image can have multiple instances of the same object, such as an image with three deer in it. It can also have multiple instances of multiple classes, like two deer and two squirrels. The word \"objects\" is often interchangeable with \"instances\", but \"instance\" is preferred because \"object\" is sometimes synonymous with \"class\"/\"category\" in everyday conversation.)\n",
    "\n",
    "To automatically crop our images, we'll use a second neural network that draws \"bounding boxes\" (aka bboxes) around any object instances, then use the coordinates of the bounding box to crop our trailcam images. A neural network that draws labeled bboxes around instances is known as an \"object detection\" model. Our object detector will be trained to recognize animals, vehicles, and people, and we'll pass the bboxes labeled \"animal\" to the animal classifier.\n",
    "\n",
    "Training a bounding box model isn't easy â€“ they require a lot more training data than classifier models. Rather than train one ourselves, we'll leverage the fantastic open source pre-trained object detection model made exactly for this purpose by the Microsoft Camera Trap team: MegaDetector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69769fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Headings",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
